{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP classifire.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PIYALI-bhunia/DEEP_LEARNING/blob/main/MLP_classifire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9TGTaTHjfaQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train , y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3kSyw8mLTy1",
        "outputId": "0c5592e0-1bf5-4229-b622-28fb1b59937a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIdqhll8a5L0",
        "outputId": "dc830dbb-6411-4ae9-843a-3cfa0818e801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(X_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "05nR0ymsRwv3",
        "outputId": "36faad73-af44-4f60-bbd4-dc8c07377d57"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1287d9a110>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "04yyFisadIIc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(layers.Flatten(input_shape= (32,32,3)))\n",
        "\n",
        "classifier.add(Dense(units= 512, kernel_initializer='he_uniform',activation='relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units= 256, kernel_initializer='he_uniform',activation='relu'))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units= 10, kernel_initializer='he_uniform', activation = 'softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "fSa_2Zq2dzQP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oAwgx7elwFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92bb7bd0-ac3c-4d5f-b4ca-bd110124259e"
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1573376   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,707,274\n",
            "Trainable params: 1,707,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the ANN to the Training set\n",
        "model_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=32, epochs = 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VERN8YuW21ib",
        "outputId": "2d455b82-fe86-432a-f143-0f205b5a3cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1047/1047 [==============================] - 8s 8ms/step - loss: 1.5571 - accuracy: 0.4433 - val_loss: 1.5935 - val_accuracy: 0.4315\n",
            "Epoch 2/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.5158 - accuracy: 0.4552 - val_loss: 1.5247 - val_accuracy: 0.4534\n",
            "Epoch 3/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.4856 - accuracy: 0.4686 - val_loss: 1.5163 - val_accuracy: 0.4662\n",
            "Epoch 4/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.4582 - accuracy: 0.4780 - val_loss: 1.5569 - val_accuracy: 0.4481\n",
            "Epoch 5/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.4368 - accuracy: 0.4869 - val_loss: 1.5271 - val_accuracy: 0.4548\n",
            "Epoch 6/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.4152 - accuracy: 0.4935 - val_loss: 1.5341 - val_accuracy: 0.4604\n",
            "Epoch 7/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.4025 - accuracy: 0.4965 - val_loss: 1.5278 - val_accuracy: 0.4667\n",
            "Epoch 8/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.3804 - accuracy: 0.5050 - val_loss: 1.5512 - val_accuracy: 0.4524\n",
            "Epoch 9/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.3620 - accuracy: 0.5123 - val_loss: 1.5214 - val_accuracy: 0.4646\n",
            "Epoch 10/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.3481 - accuracy: 0.5157 - val_loss: 1.5031 - val_accuracy: 0.4812\n",
            "Epoch 11/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.3402 - accuracy: 0.5227 - val_loss: 1.4947 - val_accuracy: 0.4775\n",
            "Epoch 12/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.3203 - accuracy: 0.5272 - val_loss: 1.4834 - val_accuracy: 0.4811\n",
            "Epoch 13/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.3106 - accuracy: 0.5322 - val_loss: 1.4864 - val_accuracy: 0.4822\n",
            "Epoch 14/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.2868 - accuracy: 0.5405 - val_loss: 1.4986 - val_accuracy: 0.4798\n",
            "Epoch 15/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.2834 - accuracy: 0.5415 - val_loss: 1.5697 - val_accuracy: 0.4647\n",
            "Epoch 16/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.2688 - accuracy: 0.5456 - val_loss: 1.5334 - val_accuracy: 0.4727\n",
            "Epoch 17/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.2551 - accuracy: 0.5497 - val_loss: 1.5041 - val_accuracy: 0.4833\n",
            "Epoch 18/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.2465 - accuracy: 0.5540 - val_loss: 1.5053 - val_accuracy: 0.4899\n",
            "Epoch 19/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.2331 - accuracy: 0.5579 - val_loss: 1.5107 - val_accuracy: 0.4876\n",
            "Epoch 20/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.2256 - accuracy: 0.5573 - val_loss: 1.4982 - val_accuracy: 0.4950\n",
            "Epoch 21/100\n",
            "1047/1047 [==============================] - 8s 8ms/step - loss: 1.2133 - accuracy: 0.5657 - val_loss: 1.5181 - val_accuracy: 0.4833\n",
            "Epoch 22/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.2022 - accuracy: 0.5685 - val_loss: 1.5246 - val_accuracy: 0.4797\n",
            "Epoch 23/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1937 - accuracy: 0.5726 - val_loss: 1.5420 - val_accuracy: 0.4812\n",
            "Epoch 24/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1909 - accuracy: 0.5733 - val_loss: 1.5516 - val_accuracy: 0.4850\n",
            "Epoch 25/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1762 - accuracy: 0.5779 - val_loss: 1.6318 - val_accuracy: 0.4709\n",
            "Epoch 26/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1680 - accuracy: 0.5819 - val_loss: 1.5562 - val_accuracy: 0.4846\n",
            "Epoch 27/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1665 - accuracy: 0.5800 - val_loss: 1.5532 - val_accuracy: 0.4834\n",
            "Epoch 28/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.1574 - accuracy: 0.5845 - val_loss: 1.5555 - val_accuracy: 0.4814\n",
            "Epoch 29/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.1445 - accuracy: 0.5893 - val_loss: 1.5729 - val_accuracy: 0.4812\n",
            "Epoch 30/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1447 - accuracy: 0.5908 - val_loss: 1.5980 - val_accuracy: 0.4876\n",
            "Epoch 31/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.1339 - accuracy: 0.5939 - val_loss: 1.5811 - val_accuracy: 0.4898\n",
            "Epoch 32/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.1216 - accuracy: 0.5982 - val_loss: 1.6044 - val_accuracy: 0.4839\n",
            "Epoch 33/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.1201 - accuracy: 0.5967 - val_loss: 1.6444 - val_accuracy: 0.4722\n",
            "Epoch 34/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.1069 - accuracy: 0.6021 - val_loss: 1.6725 - val_accuracy: 0.4683\n",
            "Epoch 35/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.1110 - accuracy: 0.5985 - val_loss: 1.6106 - val_accuracy: 0.4806\n",
            "Epoch 36/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.0958 - accuracy: 0.6055 - val_loss: 1.6446 - val_accuracy: 0.4808\n",
            "Epoch 37/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.0850 - accuracy: 0.6132 - val_loss: 1.6643 - val_accuracy: 0.4658\n",
            "Epoch 38/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0874 - accuracy: 0.6114 - val_loss: 1.6574 - val_accuracy: 0.4812\n",
            "Epoch 39/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0773 - accuracy: 0.6099 - val_loss: 1.6259 - val_accuracy: 0.4895\n",
            "Epoch 40/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.0685 - accuracy: 0.6166 - val_loss: 1.6400 - val_accuracy: 0.4787\n",
            "Epoch 41/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0684 - accuracy: 0.6145 - val_loss: 1.6798 - val_accuracy: 0.4763\n",
            "Epoch 42/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0698 - accuracy: 0.6159 - val_loss: 1.6681 - val_accuracy: 0.4790\n",
            "Epoch 43/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.0540 - accuracy: 0.6228 - val_loss: 1.7149 - val_accuracy: 0.4750\n",
            "Epoch 44/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0467 - accuracy: 0.6245 - val_loss: 1.7034 - val_accuracy: 0.4757\n",
            "Epoch 45/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.0440 - accuracy: 0.6238 - val_loss: 1.7412 - val_accuracy: 0.4755\n",
            "Epoch 46/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.0394 - accuracy: 0.6261 - val_loss: 1.6976 - val_accuracy: 0.4701\n",
            "Epoch 47/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.0341 - accuracy: 0.6294 - val_loss: 1.6797 - val_accuracy: 0.4805\n",
            "Epoch 48/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0244 - accuracy: 0.6316 - val_loss: 1.6982 - val_accuracy: 0.4708\n",
            "Epoch 49/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0216 - accuracy: 0.6333 - val_loss: 1.6982 - val_accuracy: 0.4772\n",
            "Epoch 50/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 1.0198 - accuracy: 0.6305 - val_loss: 1.7322 - val_accuracy: 0.4794\n",
            "Epoch 51/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 1.0147 - accuracy: 0.6364 - val_loss: 1.7446 - val_accuracy: 0.4823\n",
            "Epoch 52/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0098 - accuracy: 0.6373 - val_loss: 1.7665 - val_accuracy: 0.4697\n",
            "Epoch 53/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 1.0081 - accuracy: 0.6379 - val_loss: 1.7512 - val_accuracy: 0.4764\n",
            "Epoch 54/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9983 - accuracy: 0.6385 - val_loss: 1.8336 - val_accuracy: 0.4702\n",
            "Epoch 55/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9886 - accuracy: 0.6442 - val_loss: 1.8118 - val_accuracy: 0.4705\n",
            "Epoch 56/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9961 - accuracy: 0.6406 - val_loss: 1.8618 - val_accuracy: 0.4678\n",
            "Epoch 57/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9900 - accuracy: 0.6418 - val_loss: 1.8179 - val_accuracy: 0.4709\n",
            "Epoch 58/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9715 - accuracy: 0.6524 - val_loss: 1.7925 - val_accuracy: 0.4796\n",
            "Epoch 59/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9831 - accuracy: 0.6448 - val_loss: 1.7326 - val_accuracy: 0.4695\n",
            "Epoch 60/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9734 - accuracy: 0.6483 - val_loss: 1.8497 - val_accuracy: 0.4598\n",
            "Epoch 61/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9744 - accuracy: 0.6479 - val_loss: 1.7948 - val_accuracy: 0.4737\n",
            "Epoch 62/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9584 - accuracy: 0.6553 - val_loss: 1.8184 - val_accuracy: 0.4740\n",
            "Epoch 63/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9654 - accuracy: 0.6518 - val_loss: 1.8839 - val_accuracy: 0.4756\n",
            "Epoch 64/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9543 - accuracy: 0.6586 - val_loss: 1.8212 - val_accuracy: 0.4834\n",
            "Epoch 65/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9573 - accuracy: 0.6528 - val_loss: 1.8545 - val_accuracy: 0.4760\n",
            "Epoch 66/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9521 - accuracy: 0.6592 - val_loss: 1.8648 - val_accuracy: 0.4766\n",
            "Epoch 67/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9463 - accuracy: 0.6581 - val_loss: 1.9227 - val_accuracy: 0.4729\n",
            "Epoch 68/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.9480 - accuracy: 0.6590 - val_loss: 1.8961 - val_accuracy: 0.4720\n",
            "Epoch 69/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9348 - accuracy: 0.6614 - val_loss: 1.9524 - val_accuracy: 0.4591\n",
            "Epoch 70/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9264 - accuracy: 0.6637 - val_loss: 1.9266 - val_accuracy: 0.4755\n",
            "Epoch 71/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9337 - accuracy: 0.6631 - val_loss: 1.9843 - val_accuracy: 0.4719\n",
            "Epoch 72/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9195 - accuracy: 0.6663 - val_loss: 2.0101 - val_accuracy: 0.4678\n",
            "Epoch 73/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9200 - accuracy: 0.6680 - val_loss: 1.9181 - val_accuracy: 0.4790\n",
            "Epoch 74/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9215 - accuracy: 0.6676 - val_loss: 2.0054 - val_accuracy: 0.4715\n",
            "Epoch 75/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.9190 - accuracy: 0.6693 - val_loss: 1.9598 - val_accuracy: 0.4646\n",
            "Epoch 76/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.9144 - accuracy: 0.6693 - val_loss: 2.0603 - val_accuracy: 0.4645\n",
            "Epoch 77/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9096 - accuracy: 0.6731 - val_loss: 1.9655 - val_accuracy: 0.4715\n",
            "Epoch 78/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.9038 - accuracy: 0.6740 - val_loss: 1.9246 - val_accuracy: 0.4716\n",
            "Epoch 79/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.9079 - accuracy: 0.6756 - val_loss: 1.9857 - val_accuracy: 0.4693\n",
            "Epoch 80/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8989 - accuracy: 0.6739 - val_loss: 1.9964 - val_accuracy: 0.4635\n",
            "Epoch 81/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8944 - accuracy: 0.6778 - val_loss: 2.0597 - val_accuracy: 0.4664\n",
            "Epoch 82/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8954 - accuracy: 0.6757 - val_loss: 2.1020 - val_accuracy: 0.4589\n",
            "Epoch 83/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.8829 - accuracy: 0.6787 - val_loss: 2.0198 - val_accuracy: 0.4675\n",
            "Epoch 84/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.8841 - accuracy: 0.6818 - val_loss: 1.9963 - val_accuracy: 0.4727\n",
            "Epoch 85/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8853 - accuracy: 0.6756 - val_loss: 1.9550 - val_accuracy: 0.4710\n",
            "Epoch 86/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8783 - accuracy: 0.6826 - val_loss: 2.1473 - val_accuracy: 0.4607\n",
            "Epoch 87/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8846 - accuracy: 0.6822 - val_loss: 2.0348 - val_accuracy: 0.4733\n",
            "Epoch 88/100\n",
            "1047/1047 [==============================] - 8s 7ms/step - loss: 0.8733 - accuracy: 0.6861 - val_loss: 2.0532 - val_accuracy: 0.4576\n",
            "Epoch 89/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8768 - accuracy: 0.6822 - val_loss: 2.1005 - val_accuracy: 0.4659\n",
            "Epoch 90/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8570 - accuracy: 0.6883 - val_loss: 2.0286 - val_accuracy: 0.4703\n",
            "Epoch 91/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8725 - accuracy: 0.6839 - val_loss: 2.1067 - val_accuracy: 0.4727\n",
            "Epoch 92/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8711 - accuracy: 0.6852 - val_loss: 2.1372 - val_accuracy: 0.4671\n",
            "Epoch 93/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8597 - accuracy: 0.6917 - val_loss: 2.1702 - val_accuracy: 0.4662\n",
            "Epoch 94/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8562 - accuracy: 0.6928 - val_loss: 2.1955 - val_accuracy: 0.4578\n",
            "Epoch 95/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8532 - accuracy: 0.6896 - val_loss: 2.1438 - val_accuracy: 0.4690\n",
            "Epoch 96/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8453 - accuracy: 0.6953 - val_loss: 2.1379 - val_accuracy: 0.4685\n",
            "Epoch 97/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8503 - accuracy: 0.6917 - val_loss: 2.2111 - val_accuracy: 0.4630\n",
            "Epoch 98/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8485 - accuracy: 0.6930 - val_loss: 2.1540 - val_accuracy: 0.4664\n",
            "Epoch 99/100\n",
            "1047/1047 [==============================] - 7s 7ms/step - loss: 0.8470 - accuracy: 0.6921 - val_loss: 2.1929 - val_accuracy: 0.4554\n",
            "Epoch 100/100\n",
            "1047/1047 [==============================] - 6s 6ms/step - loss: 0.8329 - accuracy: 0.6985 - val_loss: 2.1122 - val_accuracy: 0.4661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "IX9v0OIsGUab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a397f833-3a72-4330-8a24-cb5b51864512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4652\n",
            "[[543  32  43  34  47  14  17  36 161  73]\n",
            " [ 55 493  27  27   9  15  21  37  87 229]\n",
            " [100  25 271  83 199  77  99  71  41  34]\n",
            " [ 44  22  88 277  91 178 123  75  48  54]\n",
            " [ 55  11  96  51 490  48 119  80  34  16]\n",
            " [ 43  15  83 191  90 335  94  79  36  34]\n",
            " [ 30  22  67  94 132  55 528  27  18  27]\n",
            " [ 49  21  54  67 112  66  39 499  25  68]\n",
            " [100  57  11  22  37  20  10  22 641  80]\n",
            " [ 61 151  14  27  16  15  18  49  74 575]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(f\"{classification_report(y_test, y_pred)}\" )"
      ],
      "metadata": {
        "id": "JkIU0GHFMdN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4551aa-0283-4c76-c8b5-5ed4cd84ebee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.54      0.52      1000\n",
            "           1       0.58      0.49      0.53      1000\n",
            "           2       0.36      0.27      0.31      1000\n",
            "           3       0.32      0.28      0.30      1000\n",
            "           4       0.40      0.49      0.44      1000\n",
            "           5       0.41      0.34      0.37      1000\n",
            "           6       0.49      0.53      0.51      1000\n",
            "           7       0.51      0.50      0.51      1000\n",
            "           8       0.55      0.64      0.59      1000\n",
            "           9       0.48      0.57      0.53      1000\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.46      0.47      0.46     10000\n",
            "weighted avg       0.46      0.47      0.46     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}